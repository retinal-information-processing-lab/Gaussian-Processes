{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0 (from utils.py)\n",
      "Using device: cuda:0 (from utils.py)\n",
      "Device is: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "import random\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "import scipy.io\n",
    "from scipy.io import loadmat\n",
    "\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm import notebook\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import importlib\n",
    "import utils\n",
    "\n",
    "# Enable autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "importlib.reload(utils)\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(0)\n",
    "    torch.cuda.manual_seed_all(0)  # if you are using multi-GPU.\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark     = False\n",
    "\n",
    "TORCH_DTYPE = torch.float64 #NB: Basically all of the matrices in Spatial_GP have 1.e-7 added to the diagonal, to be changed if we want to use float64\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "torch.set_default_dtype(TORCH_DTYPE)\n",
    "torch.set_default_device(device)\n",
    "print(f'Device is: {device}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How this works:\n",
    "\n",
    "We choose initial training points to be considered a random set of images to present to the retina. On this set, the complete GP will be run , to find STA paramaters eps_0: center, beta: width , rho: smoothness\n",
    "\n",
    "We run the algorithm saving the seed used for picking the training images, so that this set can be changed and different runs with different initial conditions can be averaged.\n",
    "\n",
    "1. Import the dataset and create a total training set X,R\n",
    "2. Pick the cell and the initial training points, extracted randomly. These correspond also to the number of inducing points\n",
    "3. Save the seed so you can keep the initial training set, and the fitted model\n",
    "3. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters of the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_xtilde = True # If True, xtilde (inducing points) are chosen randomly, if False, xtilde is chosen from the first ntilde images\n",
    "\n",
    "cellid       = 8         # Choose cell\n",
    "ntrain_start = 20        # Number of first training data points\n",
    "\n",
    "kernfun      = 'acosker' # Choose kernel function\n",
    "\n",
    "nEstep       = 8         # Total number of E-steps iterations.\n",
    "nFparamstep  = 5  \n",
    "nMstep       = 6         # Total number of M-steps iterations. \n",
    "maxiter      = 5         # Iterations of the optimization algorithm comprising M and E steps\n",
    "\n",
    "ntilde       = ntrain_start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dataset and generate starting dataset\n",
    "\n",
    "Create starting dataset on which to train with m step with ntilde = ntrain_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset memory on GPU: 281.23 MB\n"
     ]
    }
   ],
   "source": [
    "# Open the .pkl dataset file for reading in binary mode (rb)\n",
    "with open('/home/idv-eqs8-pza/IDV_code/Variational_GP/spatial_GP/Data/data2_41mixed_tr28.pkl', 'rb') as file:\n",
    "    # Load the data from the file\n",
    "    loaded_data = pickle.load(file)\n",
    "    # loaded_data is a Dataset object from module Data with attributes \"images_train, _val, _test\" as well as responses\n",
    "\n",
    "X_train = torch.tensor(loaded_data.images_train).to(device, dtype=TORCH_DTYPE) #shape (2910,108,108,1) where 108 is the number of pixels. 2910 is the amount of training points\n",
    "X_val   = torch.tensor(loaded_data.images_val).to(device, dtype=TORCH_DTYPE)\n",
    "X_test  = torch.tensor(loaded_data.images_test).to(device, dtype=TORCH_DTYPE) # shape (30,108,108,1) # nimages, npx, npx\n",
    "\n",
    "R_train = torch.tensor(loaded_data.responses_train).to(device, dtype=TORCH_DTYPE) #shape (2910,41) 2910 is the amount of training data, 41 is the number of cells\n",
    "R_val   = torch.tensor(loaded_data.responses_val).to(device, dtype=TORCH_DTYPE)\n",
    "R_test  = torch.tensor(loaded_data.responses_test).to(device, dtype=TORCH_DTYPE) # shape (30,30,42) 30 repetitions, 30 images, 42 cells\n",
    "\n",
    "# Create the complete dataset\n",
    "X = torch.cat( (X_train, X_val), axis=0,) #shape (3160,108,108,1)\n",
    "R = torch.cat( (R_train, R_val), axis=0,)\n",
    "n_px_side = X.shape[1]  \n",
    "\n",
    "# Reshape images to 1D vector and choose a cell\n",
    "X = torch.reshape(X, ( X.shape[0], X.shape[1]*X.shape[2])) \n",
    "R = R[:,cellid] # shape (nt,) where nt is the number of trials\n",
    "\n",
    "# Choose a random subset of the data and save the idx\n",
    "all_idx  = torch.arange(0, X.shape[0])                     # Indices of the whole dataset  \n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "rndm_idx = torch.randint(0, X.shape[0], (ntrain_start,))   # These will be the indices of the initial training \n",
    "\n",
    "# combined = torch.cat( (all_idx, rndm_idx) )              # Combine the indices, there are now some duplicates\n",
    "# unique, counts = combined.unique(return_counts=True)\n",
    "\n",
    "# remaining_idx = unique[counts==1]                        # Indices of the remaining data in the dataset (not yet used for training)\n",
    "# start_idx     = unique[counts>1]                         # Indices of the data used for the initial training\n",
    "# in_use_idx    = start_idx                                # Indices of the data used for training, including the initial training\n",
    "\n",
    "start_idx     = rndm_idx\n",
    "in_use_idx    = start_idx\n",
    "remaining_idx = all_idx[~torch.isin( all_idx, in_use_idx )]\n",
    "\n",
    "# Set the starting set\n",
    "xtilde_start  = X[start_idx,:]                           # In the simplest case the starting points are all inducing points\n",
    "X_remaining   = X[remaining_idx,:]\n",
    "X_in_use      = X[in_use_idx,:]\n",
    "\n",
    "R_remaining   = R[remaining_idx]\n",
    "R_in_use      = R[in_use_idx]\n",
    "\n",
    "\n",
    "# Estimate memory usage\n",
    "# Calculate memory usage for each tensor\n",
    "X_memory = X.element_size() * X.nelement()\n",
    "r_memory = R.element_size() * R.nelement()\n",
    "# Total memory usage in bytes\n",
    "total_memory_bytes = X_memory + r_memory\n",
    "# Convert bytes to megabytes (MB)\n",
    "total_memory_MB = total_memory_bytes / (1024 ** 2)\n",
    "print(f'Total dataset memory on GPU: {total_memory_MB:.2f} MB')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select cell, starting hyperparameters and firing rate parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated sigma_0 to 1.0000\n",
      "updated Amp to 1.0000\n",
      "updated eps_0x to 0.0001\n",
      "updated eps_0y to 0.0001\n",
      "updated -2log2beta to 4.8069\n",
      "updated -log2rho2 to 4.3069\n"
     ]
    }
   ],
   "source": [
    "# For details on the hyperparameters choice see one_cell_fit.ipynb\n",
    "logbetaexpr = utils.fromlogbetasam_to_logbetaexpr( logbetasam=torch.tensor(5.5) )# Logbetaexpr in this code is equal to logbeta in Samuele's code. Samuele's code set logbeta to 5.5\n",
    "logrhoexpr  = utils.fromlogrhosam_to_logrhoexpr( logrhosam=torch.tensor(5)) \n",
    "# logbetaexpr = torch.tensor(4.65)\n",
    "# logrhoexpr = torch.tensor(4.3)\n",
    "logsigma_0 = torch.tensor(0) \n",
    "sigma_0    = torch.exp(logsigma_0)\n",
    "Amp        = torch.tensor(1.0) \n",
    "eps_0x     = torch.tensor(0.0001)\n",
    "eps_0y     = torch.tensor(0.0001)\n",
    "# Hypermarameters, if needed to be set manually\n",
    "theta = {'sigma_0': sigma_0, 'Amp': Amp, 'eps_0x':eps_0x, 'eps_0y':eps_0y, '-2log2beta': logbetaexpr, '-log2rho2': logrhoexpr,  }\n",
    "\n",
    "# Set the gradient of the hyperparemters to be updatable \n",
    "for key, value in theta.items():\n",
    "    # to exclude a single hyperparemeters from the optimization ( to exclude them all just set nmstep=0 and dont do the M-step)\n",
    "    # if key == 'Amp':\n",
    "        # continue\n",
    "    theta[key] = value.requires_grad_()\n",
    "\n",
    "# If hyperparameters are set manually:\n",
    "hyperparams_tuple = utils.generate_theta( x=X_in_use, r=R_in_use, n_px_side=n_px_side, display=True, **theta)\n",
    "# If hyperparameters are set based on the STAs:\n",
    "# hyperparams_tuple = utils.generate_theta( x=X, r=r, n_px_side=n_px_side, display=True)\n",
    "\n",
    "A        = torch.tensor(0.007)\n",
    "logA     = torch.log(A)\n",
    "# lambda0  = torch.tensor(0.31)\n",
    "lambda0  = torch.tensor(1.)\n",
    "# f_params = {'logA': logA, 'loglambda0':torch.log(lambda0)}\n",
    "f_params = {'logA': logA, 'lambda0':lambda0}\n",
    "\n",
    "for key, value in f_params.items():\n",
    "    f_params[key] = value.requires_grad_()\n",
    "\n",
    "fit_parameters = {'ntilde':      ntilde,\n",
    "                  'maxiter':     maxiter,\n",
    "                  'nMstep':      nMstep,\n",
    "                  'nEstep':      nEstep,\n",
    "                  'nFparamstep': nFparamstep,\n",
    "                  'kernfun':     kernfun,\n",
    "                  'cellid':      cellid,\n",
    "                  'n_px_side':   n_px_side,}\n",
    "\n",
    "init_model = {\n",
    "        'fit_parameters':    fit_parameters,\n",
    "        'xtilde':            xtilde_start,\n",
    "        'hyperparams_tuple': hyperparams_tuple,     # Contains also the upper and lower bounds for the hyperparameters\n",
    "        'f_params':          f_params,\n",
    "        'm':                 torch.zeros( (ntilde) )\n",
    "        # 'm': torch.ones( (ntilde) )\n",
    "        #'V': dont initialize V if you want it to be initialized as K_tilde and projected _exactly_ as K_tilde_b for stabilisation\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the starting model\n",
    "And save it needed to start a new active fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization took: 0.0508 seconds\n",
      "\n",
      "Total values_track memory on GPU: 0.00 MB\n",
      "\n",
      "After initialization Allocated memory: 861.87 MB\n",
      "\n",
      "After initialization Reserved (cached) memory: 956.00 MB\n",
      "*Iteration*: 1 E-step took: 0.1927s, M-step took: 0.0501s\n",
      "*Iteration*: 2 E-step took: 0.0379s, M-step took: 0.0214s\n",
      "*Iteration*: 3 E-step took: 0.0087s, M-step took: 0.0217s\n",
      "*Iteration*: 4 E-step took: 0.0381s\n",
      "M-step skipped in the last iteration\n",
      "Final Loss: 18.1914\n",
      "\n",
      "Time spent for E-steps:       0.277s,\n",
      "Time spent for f params:      0.112s\n",
      "Time spent for m update:      0.165s\n",
      "Time spent for M-steps:       0.093s\n",
      "Time spent for X-steps:       0.371s\n",
      "Time spent computing Kernels: 0.006s\n",
      "Time spent computing Loss:    0.002s\n",
      "Time total after init:        0.383s\n",
      "Time total before init:       0.434s\n",
      "\n",
      "Final Total values_track memory on GPU: 0.01 MB\n",
      "Final Allocated memory: 871.57 MB\n",
      "Final Reserved (cached) memory: 956.00 MB\n"
     ]
    }
   ],
   "source": [
    "fit_model, err_dict = utils.varGP(X_in_use, R_in_use, **init_model)\n",
    "# fit_model, err_dict = utils.varGP(X_in_use, R_in_use, **args)\n",
    "\n",
    "# Save the model. All of the matrices are projected in the eigenspace of big eigenvalues of K_tilde. Indicated by _b\n",
    "start_model = fit_model\n",
    "\n",
    "if err_dict['is_error']:\n",
    "    print('Error in the fit')\n",
    "    raise err_dict['error']\n",
    "\n",
    "# Save the model\n",
    "# utils.save_model(start_model, f'models/starting_models_active_learning/cell:{cellid}_nstart:{ntrain_start}', additional_description='Starting model for active learning')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Old version.\n",
    "Find the most useful image and its ID. For now its estimating the utility for one at the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for lambda moments: 0.01 seconds\n",
      "\n",
      "Elapsed time for utility: 1.20 seconds\n",
      "Utility: 0.0000   |  Best image ID: 3052\n"
     ]
    }
   ],
   "source": [
    "# start_model = utils.load_model('models/starting_models_active_learning/cell:8_nstart:50')\n",
    "\n",
    "xstar = X_remaining # We call xstar the unseen images like in the notes, we will drop this notation later and just call it X_remaining\n",
    "\n",
    "with torch.no_grad():\n",
    "# reshape the remaining dataset to\n",
    "# X_remaining = torch.reshape(Xremaining, (Xremaining.shape[0], Xremaining.shape[0]*Xremaining.shape[1]))\n",
    "\n",
    "    kernfun       = start_model['fit_parameters']['kernfun']\n",
    "    mask          = start_model['mask']\n",
    "    C             = start_model['C']\n",
    "    B             = start_model['B']\n",
    "    K_tilde_b     = start_model['K_tilde_b']\n",
    "    K_tilde_inv_b = start_model['K_tilde_inv_b']\n",
    "    K_b           = start_model['K_b']\n",
    "    Kvec          = start_model['Kvec']\n",
    "    m_b           = start_model['m_b']\n",
    "    V_b           = start_model['V_b']    \n",
    "    f_params_fit  = start_model['f_params']\n",
    "    A             = torch.exp(f_params_fit['logA'])\n",
    "    lambda0       = torch.exp(f_params_fit['loglambda0']) if 'loglambda0' in f_params_fit else f_params_fit['lambda0']\n",
    "\n",
    "    start_time = time.time()\n",
    "    # Calculate the matrices to compute the lambda moments. They are referred to the unseen images xstar\n",
    "    Kvec = utils.acosker(theta, xstar[:,mask], x2=None, C=C, dC=None, diag=True)\n",
    "    K    = utils.acosker(theta, xstar[:,mask], x2=xtilde_start[:,mask], C=C, dC=None, diag=False)\n",
    "    K_b  = K @ B \n",
    "\n",
    "    lambda_m_t, lambda_var_t = utils.lambda_moments( xstar[:,mask], K_tilde_b, K_b@K_tilde_inv_b, Kvec, K_b, C, m_b, V_b, theta, kernfun)  \n",
    "    u_t                      = torch.zeros( X_remaining.shape[0] )\n",
    "    logf_mean_t              = torch.zeros( X_remaining.shape[0] )\n",
    "    logf_var_t               = torch.zeros( X_remaining.shape[0] )\n",
    "    print(f'Elapsed time for lambda moments: {time.time()-start_time:.2f} seconds')\n",
    "    start_time = time.time()\n",
    "\n",
    "    r_capped = torch.arange(0, 100, dtype=TORCH_DTYPE)\n",
    "    for i, x_idx in enumerate(remaining_idx):\n",
    "\n",
    "        logf_mean = A*lambda_m_t[i] + lambda0\n",
    "        logf_var  = A**2 * lambda_var_t[i]\n",
    "\n",
    "        u = utils.utility(logf_var, logf_mean, r_capped )\n",
    "\n",
    "        # plt.subplot(111)\n",
    "        # plt.scatter(logf_var.item(), u.item(), color=colors[r_cutoffs.index(r_cutoff)], s=10-r_cutoffs.index(r_cutoff)*5)\n",
    "        # plt.title(f'r_cutoff: {r_cutoff}')\n",
    "        # print(f'Utility: {u.item():<8.4f} |  logf_mean: {logf_mean.item():8.4f} |  logf_var: {logf_var.item():6.4f}') \n",
    "\n",
    "        u_t[i]         = u\n",
    "        logf_mean_t[i] = logf_mean\n",
    "        logf_var_t[i]  = logf_var\n",
    "        if i == 0 or u > u_best:\n",
    "            x_idx_best = x_idx\n",
    "            i_best     = i\n",
    "            u_best     = u_t[i_best]\n",
    "            \n",
    "print(f'\\nElapsed time for utility: {time.time()-start_time:.2f} seconds')  \n",
    "print(f'Utility: {u_t[i_best].item():<8.4f} |  Best image ID: {i_best}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Old version.\n",
    "Below a comparison of performance when calculating utility as a vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for utility one by one: 1.05 seconds, mean of u: 0.000000, max of u: 0.000001, min of u: 0.000000\n",
      "Elapsed time for utility as a vec  : 0.02 seconds, mean of u: 0.000000, max of u: 0.000001, min of u: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# xstar = X_remaining[0,:][None,:]\n",
    "xstar = X_remaining\n",
    "\n",
    "# Calculate the matrices to compute the lambda moments. They are referred to the unseen images xstar\n",
    "Kvec = utils.acosker(theta, xstar[:,mask], x2=None, C=C, dC=None, diag=True)\n",
    "K    = utils.acosker(theta, xstar[:,mask], x2=xtilde_start[:,mask], C=C, dC=None, diag=False)\n",
    "K_b  = K @ B \n",
    "\n",
    "lambda_m_t, lambda_var_t = utils.lambda_moments( xstar[:,mask], K_tilde_b, K_b@K_tilde_inv_b, Kvec, K_b, C, m_b, V_b, theta, kernfun)  \n",
    "r_masked = torch.arange(0, 100, dtype=TORCH_DTYPE)\n",
    "\n",
    "logf_mean = A*lambda_m_t + lambda0\n",
    "logf_var  = A**2 * lambda_var_t\n",
    "u         = torch.zeros(xstar.shape[0])\n",
    "\n",
    "start_time = time.time()\n",
    "for i, x_idx in enumerate(range(xstar.shape[0])):\n",
    "\n",
    "    u[i] = utils.utility(logf_var[i], logf_mean[i], r_masked )\n",
    "    #print(f'Utility: {u.item():<8.4f} |  logf_mean: {logf_mean[i].item():8.4f} |  logf_var: {logf_var[i].item():6.4f}') \n",
    "print(f'Elapsed time for utility one by one: {time.time()-start_time:.2f} seconds, mean of u: {u.mean():6f}, max of u: {u.max():6f}, min of u: {u.min():6f}')\n",
    "        \n",
    "start_time = time.time()\n",
    "u2d = utils.nd_utility(logf_var, logf_mean, r_masked )\n",
    "print(f'Elapsed time for utility as a vec  : {time.time()-start_time:.2f} seconds, mean of u: {u2d.mean():6f}, max of u: {u2d.max():6f}, min of u: {u2d.min():6f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the utility of each remaining image\n",
    "New version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed time for lambda moments and utility : 0.02 seconds\n"
     ]
    }
   ],
   "source": [
    "xstar = X_remaining\n",
    "\n",
    "kernfun       = start_model['fit_parameters']['kernfun']\n",
    "mask          = start_model['mask']\n",
    "C             = start_model['C']\n",
    "B             = start_model['B']\n",
    "K_tilde_b     = start_model['K_tilde_b']\n",
    "K_tilde_inv_b = start_model['K_tilde_inv_b']\n",
    "K_b           = start_model['K_b']\n",
    "Kvec          = start_model['Kvec']\n",
    "m_b           = start_model['m_b']\n",
    "V_b           = start_model['V_b']    \n",
    "f_params_fit  = start_model['f_params']\n",
    "A             = torch.exp(f_params_fit['logA'])\n",
    "lambda0       = torch.exp(f_params_fit['loglambda0']) if 'loglambda0' in f_params_fit else f_params_fit['lambda0']\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Calculate the matrices to compute the lambda moments. They are referred to the unseen images xstar\n",
    "Kvec = utils.acosker(theta, xstar[:,mask], x2=None, C=C, dC=None, diag=True)\n",
    "K    = utils.acosker(theta, xstar[:,mask], x2=xtilde_start[:,mask], C=C, dC=None, diag=False)\n",
    "K_b  = K @ B \n",
    "\n",
    "lambda_m_t, lambda_var_t = utils.lambda_moments( xstar[:,mask], K_tilde_b, K_b@K_tilde_inv_b, Kvec, K_b, C, m_b, V_b, theta, kernfun)  \n",
    "\n",
    "logf_mean = A*lambda_m_t + lambda0\n",
    "logf_var  = A**2 * lambda_var_t\n",
    "\n",
    "# Estimate the utility and cap the maximum r ( used in a summation to infinity )\n",
    "r_masked = torch.arange(0, 100, dtype=TORCH_DTYPE)\n",
    "u2d = utils.nd_utility(logf_var, logf_mean, r_masked )\n",
    "print(f'\\nElapsed time for lambda moments and utility : {time.time()-start_time:.2f} seconds')  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the index(es) for the most useful image \n",
    "Check the correspondence between the index: ```i_best``` of the ```xstar = X_remaining``` images with the one: ```x_idx_best```  for the complete dataset ```X```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utility: 0.0000   |  Best image ID: 3052  | Best image index: 3072\n",
      " this has utility tensor([5.0517e-07], device='cuda:0') and f_mean :  0.1500\n",
      " this has utility tensor([5.0517e-07], device='cuda:0') and f_mean :  0.1500\n"
     ]
    }
   ],
   "source": [
    "i_best     = u2d.argmax()\n",
    "x_idx_best = remaining_idx[i_best]\n",
    "print(f'Utility: {u2d[i_best].item():<8.4f} |  Best image ID: {i_best}  | Best image index: {x_idx_best}')\n",
    "\n",
    "Kvec = utils.acosker(theta, xstar[:,mask], x2=None, C=C, dC=None, diag=True)\n",
    "K    = utils.acosker(theta, xstar[:,mask], x2=xtilde_start[:,mask], C=C, dC=None, diag=False)\n",
    "K_b  = K @ B \n",
    "lambda_m_t, lambda_var_t = utils.lambda_moments( xstar[:,mask], K_tilde_b, K_b@K_tilde_inv_b, Kvec, K_b, C, m_b, V_b, theta, kernfun)  \n",
    "logf_mean = A*lambda_m_t + lambda0\n",
    "logf_var  = A**2 * lambda_var_t\n",
    "print(f' this has utility {utils.nd_utility(logf_var[i_best], logf_mean[i_best], r_masked)} and f_mean :{torch.exp(logf_mean[i_best]).item():8.4f}')\n",
    "\n",
    "# Calculate the matrices to compute the lambda moments. They are referred to the unseen images xstar\n",
    "Kvec = utils.acosker(theta, X[x_idx_best,mask][None,:], x2=None, C=C, dC=None, diag=True)\n",
    "K    = utils.acosker(theta, X[x_idx_best,mask][None,:], x2=xtilde_start[:,mask], C=C, dC=None, diag=False)\n",
    "K_b  = K @ B \n",
    "lambda_m_t, lambda_var_t = utils.lambda_moments( X[x_idx_best,mask][None,:], K_tilde_b, K_b@K_tilde_inv_b, Kvec, K_b, C, m_b, V_b, theta, kernfun)  \n",
    "logf_mean = A*lambda_m_t + lambda0\n",
    "logf_var  = A**2 * lambda_var_t\n",
    "print(f' this has utility {utils.nd_utility(logf_var, logf_mean, r_masked)} and f_mean :{torch.exp(logf_mean).item():8.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update the indexes tensors and fit the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization took: 0.0046 seconds\n",
      "\n",
      "*Iteration*: 0 E-step took: 0.3310s, M-step took: 0.2420s\n",
      "*Iteration*: 1 E-step took: 0.2831s, M-step took: 0.2267s\n",
      "*Iteration*: 2 E-step took: 0.2814s\n",
      "M-step skipped in the last iteration\n",
      "\n",
      "E-steps took in total: 0.8955s\n",
      "M-steps took in total: 0.4688s\n",
      "Final Loss: 17.7385\n",
      "      time for final loss computation: 0.0018 s\n",
      "Total time for GP:                     1.4582 s\n"
     ]
    }
   ],
   "source": [
    "# Update the used and remaining indices\n",
    "in_use_idx    = torch.unique(torch.cat( (in_use_idx, x_idx_best[None])))  \n",
    "remaining_idx = all_idx[~torch.isin( all_idx, in_use_idx )]\n",
    "\n",
    "X_in_use    = X[in_use_idx]\n",
    "R_in_use    = R[in_use_idx] \n",
    "X_remaining = X[remaining_idx]\n",
    "R_remaining = R[remaining_idx]\n",
    "\n",
    "# The added images are used as inducing points as long as the number of inducing points is less than 200\n",
    "if in_use_idx.shape[0] < 200:\n",
    "    ntilde = in_use_idx.shape[0]\n",
    "    xtilde_updated = X_in_use\n",
    "\n",
    "start_model['xtilde'] = xtilde_updated\n",
    "start_model['fit_parameters']['ntilde'] = ntilde\n",
    "\n",
    "fit_model, err_dict = utils.varGP(X_in_use, R_in_use, **start_model)\n",
    "\n",
    "if err_dict['is_error']:\n",
    "    print('Error in the fit')\n",
    "    raise err_dict['error']\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The training set has been updated and so has the xtilde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of starting points 10, Number of to be used points    11\n",
      "Number of initial ntilde  10, Number of to be updated ntilde 11\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of starting points {X[start_idx].shape[0]}, Number of to be used points    {X_in_use.shape[0]}')\n",
    "print(f'Number of initial ntilde  {xtilde_start.shape[0]}, Number of to be updated ntilde {xtilde_updated.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 11664])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_model['xtilde'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop like this until the selected amount of images has been shown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m n_imgs_to_show \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m200\u001b[39m\n\u001b[0;32m----> 2\u001b[0m r_capped \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m100\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mTORCH_DTYPE)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_imgs_to_show):\n\u001b[1;32m      5\u001b[0m     start_time_utility \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "n_imgs_to_show = 200\n",
    "r_capped = torch.arange(0, 100, dtype=TORCH_DTYPE)\n",
    "for j in range(n_imgs_to_show):\n",
    "\n",
    "    start_time_utility = time.time()\n",
    "\n",
    "    kernfun        = fit_model['fit_parameters']['kernfun']\n",
    "    theta          = fit_model['hyperparams_tuple'][0]\n",
    "    xtilde_updated = fit_model['xtilde']\n",
    "    K_tilde_b      = fit_model['K_tilde_b']\n",
    "    K_tilde_inv_b  = fit_model['K_tilde_inv_b']\n",
    "    B              = fit_model['B']\n",
    "    C              = fit_model['C']\n",
    "    m_b            = fit_model['m_b']\n",
    "    V_b            = fit_model['V_b']\n",
    "    mask           = fit_model['mask']\n",
    "\n",
    "    # The matrices to compute the lambda moments are calculated on the unseen images X_remaining (xstar)\n",
    "    Kvec = utils.acosker(theta, X_remaining[:,mask], x2=None,                   C=C, dC=None, diag=True)\n",
    "    K    = utils.acosker(theta, X_remaining[:,mask], x2=xtilde_updated[:,mask], C=C, dC=None, diag=False)\n",
    "    K_b  = K @ B \n",
    "\n",
    "    lambda_m_t, lambda_var_t = utils.lambda_moments( X_remaining[:,mask], K_tilde_b, K_b@K_tilde_inv_b, Kvec, K_b, C, m_b, V_b, theta, kernfun)  \n",
    "\n",
    "    logf_mean = A*lambda_m_t + lambda0\n",
    "    logf_var  = A**2 * lambda_var_t\n",
    "\n",
    "    # Estimate the utility with a cappet .arange() vector r( used in a summation to infinity )\n",
    "    u2d = utils.nd_utility(logf_var, logf_mean, r_capped )\n",
    "\n",
    "    i_best     = u2d.argmax()\n",
    "    x_idx_best = remaining_idx[i_best]\n",
    "\n",
    "    in_use_idx    = torch.unique(torch.cat( (in_use_idx, x_idx_best[None]) ))\n",
    "    remaining_idx = all_idx[~torch.isin( all_idx, in_use_idx )]\n",
    "\n",
    "    X_in_use    = X[in_use_idx]\n",
    "    R_in_use    = R[in_use_idx] \n",
    "    X_remaining = X[remaining_idx]\n",
    "    R_remaining = R[remaining_idx]\n",
    "\n",
    "    # The added images are used as inducing points as long as the number of inducing points is less than 200\n",
    "    if in_use_idx.shape[0] < 200:\n",
    "        ntilde = in_use_idx.shape[0]\n",
    "        xtilde_updated = X[in_use_idx]\n",
    "\n",
    "    print(f'Best utility: {u2d[i_best].item():<8.4f} | Mean Utility {u2d.mean().item():<8.4f} |  Best image ID: {i_best} | Best image index: {x_idx_best} | Elapsed time for utility: {time.time()-start_time_utility:.2f} seconds')\n",
    "\n",
    "\n",
    "    fit_model['xtilde'] = xtilde_updated\n",
    "    fit_model['fit_parameters']['ntilde'] = ntilde\n",
    "\n",
    "    fit_model, err_dict = utils.varGP(X_in_use, R_in_use, **fit_model)\n",
    "\n",
    "    if err_dict['is_error']:\n",
    "        print(f'Error in the fit while adding image n {j}')\n",
    "        raise err_dict['error'] "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
