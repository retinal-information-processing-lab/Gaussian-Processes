{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0 (from utils.py)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# sys.path.insert(0, '/home/idv-eqs8-pza/IDV_code/Variational_GP/spatial_GP')\n",
    "import time\n",
    "import random\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "import scipy.io\n",
    "from scipy.io import loadmat\n",
    "\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm import notebook\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import *\n",
    "\n",
    "TORCH_DTYPE = torch.float32\n",
    "# Set the default dtype to float32\n",
    "torch.set_default_dtype(TORCH_DTYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters of the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_xtilde = False # If True, xtilde (inducing points) are chosen randomly, if False, xtilde is chosen from the first ntilde images\n",
    "noise       = False # If True, noise is added to xtilde (used to avoid inducing points being too close to each other in their space)\n",
    "rescale     = False # If True, X is rescaled between -1 and 1\n",
    "cellid      = 1   # Choose cell\n",
    "ntilde      = 50   # Number of xtilde\n",
    "kernfun     = acosker # Choose kernel function\n",
    "\n",
    "Nmstep  = 1\n",
    "Nestep  = 1\n",
    "Maxiter = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the dataset and preprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device is: cuda:0\n"
     ]
    }
   ],
   "source": [
    "##################\n",
    "#  Factor 1/2 is removed from acosker\n",
    "##################\n",
    "\n",
    "# Set the device and dtype\n",
    "torch_dtype = torch.float32 # NB: Basically all of the matrices in Spatial_GP have 1.e-7 added to the diagonal, to be changed if we want to use float64\n",
    "# torch_dtype = torch.float64\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "torch.set_default_dtype(torch_dtype)\n",
    "torch.set_default_device(device)\n",
    "print(f'Device is: {device}')\n",
    "\n",
    "\n",
    "    \n",
    "# Open the .pkl dataset file for reading in binary mode (rb)\n",
    "with open('/home/idv-eqs8-pza/IDV_code/Variational_GP/spatial_GP/Data/data2_41mixed_tr28.pkl', 'rb') as file:\n",
    "    # Load the data from the file\n",
    "    loaded_data = pickle.load(file)\n",
    "    # loaded_data is a Dataset object from module Data with attributes \"images_train, _val, _test\" as well as responses\n",
    "\n",
    "X_train = torch.tensor(loaded_data.images_train).to(device) #shape (2910,108,108,1) where 108 is the number of pixels. 2910 is the amount of training data\n",
    "X_val   = torch.tensor(loaded_data.images_val).to(device)\n",
    "X_test  = torch.tensor(loaded_data.images_test).to(device) # shape (30,108,108,1) # nimages, npx, npx\n",
    "\n",
    "R_train = torch.tensor(loaded_data.responses_train).to(device, dtype=torch_dtype) #shape (2910,41) 2910 is the amount of training data, 41 is the number of cells\n",
    "R_val   = torch.tensor(loaded_data.responses_val).to(device, dtype=torch_dtype)\n",
    "R_test   = torch.tensor(loaded_data.responses_test).to(device, dtype=torch_dtype) # shape (30,30,42) 30 repetitions, 30 images, 42 cells\n",
    "\n",
    "# Concatenate Xtrain and Xval if not using validation set \n",
    "X = torch.cat( (X_train, X_val), axis=0,) #shape (3160,108,108,1)\n",
    "R = torch.cat( (R_train, R_val), axis=0,)\n",
    "# X = X_train\n",
    "# R = R_train\n",
    "\n",
    "# Rescale X to be between -1 and 1\n",
    "if rescale == True:\n",
    "    X = (X - X.min()) / (X.max() - X.min()) * 2 - 1\n",
    "\n",
    "# Choose a cell\n",
    "r = R[:,cellid] # shape (nt,) where nt is the number of trials\n",
    "\n",
    "# Reshape images to 1D vector\n",
    "n_px_side = X.shape[1] # 108   \n",
    "X = torch.reshape(X, ( X.shape[0], X.shape[1]*X.shape[2])) # shape (n x , 11664)=(nt, nx)\n",
    "# If X_val is being used, reshape it\n",
    "# X_val = torch.reshape(X_val, ( X_val.shape[0], X_val.shape[1]*X_val.shape[2])) # shape (n x val, 11664)=(nt, nx)\n",
    "\n",
    "if rand_xtilde == True:\n",
    "    torch.manual_seed(2024)\n",
    "    indices = torch.randint(0, X.shape[0], (ntilde,))\n",
    "else:\n",
    "    indices = torch.arange(0,ntilde, dtype=torch.int64)\n",
    "if noise == True:\n",
    "    xtilde = X[indices,:] + 1e-7*torch.rand(X[indices,:].shape)*2 - 1.e-7\n",
    "else:\n",
    "    xtilde = X[indices,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated sigma_0 to 1.0\n",
      "updated eps_0x to 0.0\n",
      "updated eps_0y to 0.0\n",
      "updated -2log2beta to 4.8068528175354\n",
      "updated -log2rho2 to 4.3068528175354\n",
      "updated Amp to 1.0\n",
      " Before overloading\n",
      " Hyperparameters have been SET as  : beta = 0.05856070, rho = 0.02928035\n",
      " Samuele hyperparameters           : logbetasam = 4.9822, logrhosam = 7.0617\n",
      "\n",
      " After overloading\n",
      " Dict of learnable hyperparameters : sigma_0 = 1.00000000, eps_0x = 0.00000000, eps_0y = 0.00000000, -2log2beta = 4.80685282, -log2rho2 = 4.30685282, Amp = 1.00000000\n",
      " Hyperparameters from the logexpr  : beta = 0.04520382, rho = 0.08208501\n",
      " Samuele hyperparameters           : logbetasam = 5.5000, logrhosam = 5.0000\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/idv-eqs8-pza/anaconda3/envs/pytorch/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_13490/2976481276.py\", line 32, in <module>\n",
      "    theta, f_params, m, V, C, mask, K_tilde_inv, K_tilde, values_track = varGP(X, r, **args)\n",
      "                                                                         ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/idv-eqs8-pza/IDV_code/Variational_GP/Spatial_GP_repo/utils.py\", line 1010, in varGP\n",
      "    C, mask = localker(nx=x.shape[1], theta=theta, theta_higher_lims=theta_higher_lims, theta_lower_lims=theta_lower_lims, n_px_side=n_px_side, grad=False) #TODO check that the shape is correct for any input shape\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/idv-eqs8-pza/IDV_code/Variational_GP/Spatial_GP_repo/utils.py\", line 359, in localker\n",
      "    return C, mask#, #dC # shape of C: (nx, nx)\n",
      "                    ^^\n",
      "NameError: name 'dC' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/idv-eqs8-pza/anaconda3/envs/pytorch/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 2120, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/idv-eqs8-pza/anaconda3/envs/pytorch/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/idv-eqs8-pza/anaconda3/envs/pytorch/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/idv-eqs8-pza/anaconda3/envs/pytorch/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/idv-eqs8-pza/anaconda3/envs/pytorch/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/idv-eqs8-pza/anaconda3/envs/pytorch/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/idv-eqs8-pza/anaconda3/envs/pytorch/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/idv-eqs8-pza/anaconda3/envs/pytorch/lib/python3.11/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/home/idv-eqs8-pza/anaconda3/envs/pytorch/lib/python3.11/site-packages/stack_data/core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/idv-eqs8-pza/anaconda3/envs/pytorch/lib/python3.11/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/home/idv-eqs8-pza/anaconda3/envs/pytorch/lib/python3.11/site-packages/stack_data/core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/idv-eqs8-pza/anaconda3/envs/pytorch/lib/python3.11/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/home/idv-eqs8-pza/anaconda3/envs/pytorch/lib/python3.11/site-packages/stack_data/core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "           ^^^^^\n",
      "  File \"/home/idv-eqs8-pza/anaconda3/envs/pytorch/lib/python3.11/site-packages/executing/executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# If one wants to compare the hyperparemeters set in Samuele's code:\n",
    "logsigma_0 = torch.tensor(0) # Samuele's code set the log of sigma\n",
    "\n",
    "logbetaexpr = fromlogbetasam_to_logbetaexpr( logbetasam=torch.tensor(5.5) )# Logbetaexpr in this code is equal to logbeta in Samuele's code. Samuele's code set logbeta to 5.5\n",
    "\n",
    "logrhoexpr  = fromlogrhosam_to_logrhoexpr( logrhosam=torch.tensor(5)) \n",
    "\n",
    "Amp = torch.tensor(1.0) # Samuele's code set Amp to 1 does not learn it (absent in the code)\n",
    "\n",
    "theta = {'sigma_0': torch.exp(logsigma_0), 'eps_0x':torch.tensor(0.0), 'eps_0y':torch.tensor(0.0), '-2log2beta': logbetaexpr, '-log2rho2': logrhoexpr, 'Amp': Amp }\n",
    "\n",
    "for key, value in theta.items():\n",
    "    theta[key] = value.requires_grad_()\n",
    "\n",
    "hyperparams_tuple = generate_theta( x=X, r=r, n_px_side=n_px_side, display=True, **theta)\n",
    "\n",
    "\n",
    "args = {\n",
    "        'ntilde':  ntilde,\n",
    "        'Maxiter': Maxiter,\n",
    "        'Nmstep':  Nmstep,\n",
    "        'Nestep':  Nestep,\n",
    "        'kernfun': kernfun,\n",
    "        'n_px_side': n_px_side,\n",
    "        'display_hyper': True,\n",
    "        'display_prog':  True,\n",
    "        'hyperparams_tuple': hyperparams_tuple,\n",
    "    }\n",
    "\n",
    "# Train model\n",
    "theta, f_params, m, V, C, mask, K_tilde_inv, K_tilde, values_track = varGP(X, r, **args)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the model\n",
    "model = {\n",
    "    'theta': theta,\n",
    "    'f_params': f_params,\n",
    "    'm': m,\n",
    "    'V': V,\n",
    "    'C': C,\n",
    "    'mask': mask,\n",
    "    'K_tilde_inv': K_tilde_inv,\n",
    "    'K_tilde': K_tilde,\n",
    "    'cellid': cellid,\n",
    "    'ntilde': ntilde,\n",
    "    'Maxiter': Maxiter,\n",
    "    'Nmstep': Nmstep,\n",
    "    'Nestep': Nestep,\n",
    "    'kernfun': kernfun,\n",
    "    'values_track': values_track,\n",
    "}\n",
    "\n",
    "# save_pickle('pietro_model', **model)\n",
    "\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "# TEMP\n",
    "# To compare to samuele I have to kep the aplitude of C fixed to 1, he does not have it\n",
    "theta['Amp'] = 1.0\n",
    "\n",
    "\n",
    "print(f'f_params: {f_params}')\n",
    "for key, value in theta.items():\n",
    "    print(f\"{key}: {value:.4f}\")\n",
    "\n",
    "# Predict and test\n",
    "\n",
    "rtst, R_predicted, r2, sigma_r2 = test(X_test, R_test, xtilde, **model )\n",
    "\n",
    "# Plot results\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "gs = fig.add_gridspec(5, 5,\n",
    "            left=0.1, right=0.9, bottom=0.1, top=0.9,\n",
    "            wspace=0.3, hspace=0.7)\n",
    "dt = 0.05\n",
    "time_values = dt * np.arange( len(R_predicted) )\n",
    "ax = fig.add_subplot(gs[3:, :])\n",
    "ax.plot(time_values, np.mean(rtst, axis=0) / 0.05, 'k', linewidth=1)\n",
    "\n",
    "ax.plot(time_values, R_predicted / 0.05, color='red', label='GP')\n",
    "# ax.errorbar(time_values, R_predicted / 0.05, yerr=np.sqrt(sigma2_f[:,0].cpu()) / 0.05, color='red')\n",
    "# ax.legend(['data', 'GP'], loc='upper right', fontsize=14)\n",
    "txt = f'Pietro adjusted r^2 = {r2:.2f} ± {sigma_r2:.2f} Cell: {cellid}'\n",
    "ax.set_title(f'{txt}')\n",
    "# ax.set_ylabel('Firing rate (Hz)')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "\n",
    "a=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
